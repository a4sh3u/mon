#
# Copyright (c) 2016, ubitricity Gesellschaft fÃ¼r Verteilte Energiesysteme mbH,
# Berlin, Germany
#
# All rights reserved. Dissemination, reproduction, or use of this material in source
# and binary forms requires prior written permission from ubitricity.
#
# Logstash filter rules for backend log analysis.
# bim:

filter {

    # The BIM application log.
    if [fields][app] == "bim" and [fields][log] == "application" {

        grok {
            patterns_dir => ["/etc/logstash/patterns"]
            # general line
            match => [ "message", "\[%{TIMESTAMP_ISO8601:datetime}\] \[(?<thread>.+)\] %{LOGLEVEL:log_level} +\[?\/?%{WORD:class}\]?\:%{BASE10NUM:line_in_class} - (?<data>.*)" ]
        }

        # drop DEBUG messages:
        if ([log_level] == "DEBUG") {
            drop {}
        }

        # drop messages not starting with a timestamp
        if !([datetime]) {
            drop{}
        }

        # rename message body to error_msg
        if ([log_level] == "ERROR") or ([log_level] == "WARN")  {
            mutate {
                rename => { "data" => "error_msg" }
            }
        }

        if ([log_level] == "TRACE") {

            if ([data] =~ /^Received.+billing.+data:.+/) {
                grok {
                    patterns_dir => ["/etc/logstash/patterns"]
                    match => [ "data", "Received billing data: BillingChargingEventDto.+mmId=MmId\{mmId=%{MM_ID:mm_id}\}, mmCDRCounter=Counter\{counter=%{COUNTER:mm_cdr_counter}\}, ssoId=SsoId\{ssoId=%{SSO_ID:sso_id}\}, ssoAuthorizationCounter=Counter\{counter=%{COUNTER:sso_authorization_counter}\}.+reportType=%{CDR_REPORT_TYPE:cdr_report_type}.+mec=(?<mec_tmp>(null)|(.+cpp))=(?<cpp_tmp>(null)|(.+fec))=(?<fec_tmp>(null)|(.+mes))=(?<mes_tmp>(null)|(.+clearingVariant))=(?<clearing_variant>[A-Z]),.+customerConfluence=(?<customer_confluence>[A-Z_]+),.+" ]
                    add_field => { "event" => "billing-charging-event-received" }
                }

                if([mec_tmp] != "null, cpp") {
                    grok {
                        patterns_dir => ["/etc/logstash/patterns"]
                        match => [ "mec_tmp", ".+customerNumber=(?<mec_customer_number>[a-zA-z0-9]+).+contractNumber=(?<mec_contract_number>[a-zA-z0-9\-]+).+" ]
                    }
                }

                if([cpp_tmp] != "null, fec") {
                    grok {
                        patterns_dir => ["/etc/logstash/patterns"]
                        match => [ "cpp_tmp", ".+customerNumber=(?<cpp_customer_number>[a-zA-z0-9]+).+contractNumber=(?<cpp_contract_number>[a-zA-z0-9\-]+).+" ]
                    }
                }

                if([fec_tmp] != "null, mes") {
                    grok {
                        patterns_dir => ["/etc/logstash/patterns"]
                        match => [ "fec_tmp", ".+customerNumber=(?<fec_customer_number>[a-zA-z0-9]+).+contractNumber=(?<fec_contract_number>[a-zA-z0-9\-]+).+" ]
                    }
                }

                if([mes_tmp] != "null, clearingVariant") {
                    grok {
                        patterns_dir => ["/etc/logstash/patterns"]
                        match => [ "mes_tmp", ".+customerNumber=(?<mes_customer_number>[a-zA-z0-9]+).+contractNumber=(?<mes_contract_number>[a-zA-z0-9\-]+).+" ]
                    }
                }

            }

        }

        # remove field data as the whole message is stored in the index as well
        # remove temporary fields used for parsing parts of the BillingChargingEventDto
        mutate {
            remove_field => [ "data" ]
            remove_field => [ "mec_tmp" ]
            remove_field => [ "cpp_tmp" ]
            remove_field => [ "fec_tmp" ]
            remove_field => [ "mes_tmp" ]
        }

    }

    #add timezone to timestamp format
    date {
        match => [ "datetime", "YYYY-MM-dd HH:mm:ss,SSS" ]
        timezone => "Etc/UTC"
        remove_field => [ "datetime" ]
    }

}
